# Speech-Emotion-Detection-Using-Deep-Learning-and-Audio-Signal-Processing
Speech emotion detection plays a vital role in human-computer interaction by enabling systems to interpret and respond to human emotions effectively. This project presents a deep learningbased approach to classify emotions from speech signals using a combination of signal processing techniques and 1D Convolutional Neural Networks (CNNs)The model utilizes prominent audio features such as Mel-Frequency Cepstral Coefficients (MFCCs), Zero Crossing Rate (ZCR), Chroma Features, Root Mean Square (RMS) Energy, and Mel Spectrograms, extracted using the librosa library. To enhance the robustness of the model, data augmentation techniques, including noise addition, time-stretching, pitch shifting,and signal shifting, were employed, significantly diversifying the training dataset.The model was trained and evaluated on benchmark datasets such as RAVDESS, CREMA-D, and SAVEE, achieving a high classification accuracy in detecting eight distinct emotions: neutral, calm, happy, sad, angry, fear, disgust, and surprise.
